{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73689f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Exp 3 CNN WITH PYTORCH\n",
    "## Name: V DIVYASHREE\n",
    "## Register Number: 212223230051"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "481af3ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting torchsummary\n",
      "  Downloading torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\n",
      "Installing collected packages: torchsummary\n",
      "Successfully installed torchsummary-1.5.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09d61031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.23.0-cp311-cp311-win_amd64.whl (1.6 MB)\n",
      "                                              0.0/1.6 MB ? eta -:--:--\n",
      "                                              0.0/1.6 MB ? eta -:--:--\n",
      "     -                                        0.0/1.6 MB 388.9 kB/s eta 0:00:05\n",
      "     --                                       0.1/1.6 MB 744.7 kB/s eta 0:00:03\n",
      "     --                                       0.1/1.6 MB 653.6 kB/s eta 0:00:03\n",
      "     --                                       0.1/1.6 MB 653.6 kB/s eta 0:00:03\n",
      "     --                                       0.1/1.6 MB 653.6 kB/s eta 0:00:03\n",
      "     --                                       0.1/1.6 MB 653.6 kB/s eta 0:00:03\n",
      "     --                                       0.1/1.6 MB 653.6 kB/s eta 0:00:03\n",
      "     --                                       0.1/1.6 MB 653.6 kB/s eta 0:00:03\n",
      "     --                                       0.1/1.6 MB 653.6 kB/s eta 0:00:03\n",
      "     --                                       0.1/1.6 MB 653.6 kB/s eta 0:00:03\n",
      "     -----                                    0.2/1.6 MB 423.5 kB/s eta 0:00:04\n",
      "     ------                                   0.3/1.6 MB 424.5 kB/s eta 0:00:04\n",
      "     --------                                 0.3/1.6 MB 524.3 kB/s eta 0:00:03\n",
      "     -----------                              0.5/1.6 MB 669.8 kB/s eta 0:00:02\n",
      "     ------------                             0.5/1.6 MB 684.7 kB/s eta 0:00:02\n",
      "     ------------                             0.5/1.6 MB 684.7 kB/s eta 0:00:02\n",
      "     ------------                             0.5/1.6 MB 684.7 kB/s eta 0:00:02\n",
      "     ------------                             0.5/1.6 MB 684.7 kB/s eta 0:00:02\n",
      "     --------------                           0.6/1.6 MB 633.1 kB/s eta 0:00:02\n",
      "     --------------------                     0.8/1.6 MB 869.4 kB/s eta 0:00:01\n",
      "     ------------------------                 1.0/1.6 MB 952.3 kB/s eta 0:00:01\n",
      "     ------------------------                 1.0/1.6 MB 932.7 kB/s eta 0:00:01\n",
      "     ------------------------                 1.0/1.6 MB 932.7 kB/s eta 0:00:01\n",
      "     ------------------------                 1.0/1.6 MB 885.6 kB/s eta 0:00:01\n",
      "     ---------------------------              1.1/1.6 MB 893.0 kB/s eta 0:00:01\n",
      "     ------------------------------           1.2/1.6 MB 1.0 MB/s eta 0:00:01\n",
      "     ------------------------------------     1.5/1.6 MB 1.1 MB/s eta 0:00:01\n",
      "     --------------------------------------   1.5/1.6 MB 1.2 MB/s eta 0:00:01\n",
      "     --------------------------------------   1.5/1.6 MB 1.2 MB/s eta 0:00:01\n",
      "     --------------------------------------   1.5/1.6 MB 1.2 MB/s eta 0:00:01\n",
      "     --------------------------------------   1.5/1.6 MB 1.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------  1.6/1.6 MB 1.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.6/1.6 MB 1.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from torchvision) (1.24.3)\n",
      "Requirement already satisfied: torch==2.8.0 in c:\\users\\admin\\appdata\\roaming\\python\\python311\\site-packages (from torchvision) (2.8.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from torchvision) (9.4.0)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from torch==2.8.0->torchvision) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\admin\\appdata\\roaming\\python\\python311\\site-packages (from torch==2.8.0->torchvision) (4.14.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\admin\\appdata\\roaming\\python\\python311\\site-packages (from torch==2.8.0->torchvision) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\programdata\\anaconda3\\lib\\site-packages (from torch==2.8.0->torchvision) (2.8.4)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch==2.8.0->torchvision) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\programdata\\anaconda3\\lib\\site-packages (from torch==2.8.0->torchvision) (2023.3.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch==2.8.0->torchvision) (1.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->torch==2.8.0->torchvision) (2.1.1)\n",
      "Installing collected packages: torchvision\n",
      "Successfully installed torchvision-0.23.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2cb8bd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85ab9ff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9.91M/9.91M [00:09<00:00, 1.09MB/s]\n",
      "100%|██████████| 28.9k/28.9k [00:00<00:00, 90.5kB/s]\n",
      "100%|██████████| 1.65M/1.65M [00:03<00:00, 476kB/s] \n",
      "100%|██████████| 4.54k/4.54k [00:00<00:00, 1.07MB/s]\n"
     ]
    }
   ],
   "source": [
    "transform=transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,),(0.5,))])\n",
    "train_dataset=torchvision.datasets.MNIST(root='./data',train=True,download=True,transform=transform)\n",
    "test_dataset=torchvision.datasets.MNIST(root='./data',train=False,download=True,transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b183821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: torch.Size([1, 28, 28])\n",
      "Number of training samples: 60000\n",
      "Image shape: torch.Size([1, 28, 28])\n",
      "Number of testing samples: 10000\n"
     ]
    }
   ],
   "source": [
    "image,label=train_dataset[0]\n",
    "print(\"Image shape:\",image.shape)\n",
    "print(\"Number of training samples:\",len(train_dataset))\n",
    "\n",
    "image,label=test_dataset[0]\n",
    "print(\"Image shape:\",image.shape)\n",
    "print(\"Number of testing samples:\",len(test_dataset))\n",
    "train_loader=DataLoader(train_dataset,batch_size=32,shuffle=True)\n",
    "test_loader=DataLoader(test_dataset,batch_size=32,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af1ccd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNClassifier(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(CNNClassifier,self).__init__()\n",
    "    self.conv1=nn.Conv2d(in_channels=1,out_channels=32,kernel_size=3,padding=1)\n",
    "    self.conv2=nn.Conv2d(in_channels=32,out_channels=64,kernel_size=3,padding=1)\n",
    "    self.conv3=nn.Conv2d(in_channels=64,out_channels=128,kernel_size=3,padding=1)\n",
    "    self.pool=nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "    self.fc1=nn.Linear(128*3*3,128)\n",
    "    self.fc2=nn.Linear(128,64)\n",
    "    self.fc3=nn.Linear(64,10)\n",
    "\n",
    "  def forward(self,x):\n",
    "    x=self.pool(t.relu(self.conv1(x)))\n",
    "    x=self.pool(t.relu(self.conv2(x)))\n",
    "    x=self.pool(t.relu(self.conv3(x)))\n",
    "    x=x.view(x.size(0),-1)\n",
    "    x=nn.functional.relu(self.fc1(x))\n",
    "    x=nn.functional.relu(self.fc2(x))\n",
    "    x=self.fc3(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79435e49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: DIVYASHREE V\n",
      "Reg.no: 212223230051\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 28, 28]             320\n",
      "         MaxPool2d-2           [-1, 32, 14, 14]               0\n",
      "            Conv2d-3           [-1, 64, 14, 14]          18,496\n",
      "         MaxPool2d-4             [-1, 64, 7, 7]               0\n",
      "            Conv2d-5            [-1, 128, 7, 7]          73,856\n",
      "         MaxPool2d-6            [-1, 128, 3, 3]               0\n",
      "            Linear-7                  [-1, 128]         147,584\n",
      "            Linear-8                   [-1, 64]           8,256\n",
      "            Linear-9                   [-1, 10]             650\n",
      "================================================================\n",
      "Total params: 249,162\n",
      "Trainable params: 249,162\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.42\n",
      "Params size (MB): 0.95\n",
      "Estimated Total Size (MB): 1.37\n",
      "----------------------------------------------------------------\n",
      "Name: DIVYASHREE V\n",
      "Reg.no: 212223230051\n",
      "Epoch [1/10], Loss: 0.1570\n",
      "Epoch [2/10], Loss: 0.0462\n",
      "Epoch [3/10], Loss: 0.0347\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "model=CNNClassifier()\n",
    "if t.cuda.is_available():\n",
    "  device=t.device(\"cuda\")\n",
    "  model.to(device)\n",
    "print(\"Name: DIVYASHREE V\")\n",
    "print(\"Reg.no: 212223230051\")\n",
    "summary(model,input_size=(1,28,28))\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "optimizer=optim.Adam(model.parameters(),lr=0.001)\n",
    "def train_model(model,train_loader,num_epochs):\n",
    "  for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss=0.0\n",
    "    for images,labels in train_loader:\n",
    "      if t.cuda.is_available():\n",
    "        images,labels=images.to(device),labels.to(device)\n",
    "      optimizer.zero_grad()\n",
    "      outputs=model(images)\n",
    "      loss=criterion(outputs,labels)\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      running_loss+=loss.item()\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n",
    "print(\"Name: DIVYASHREE V\")\n",
    "print(\"Reg.no: 212223230051\")\n",
    "\n",
    "train_model(model,train_loader,num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40d5b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_loader):\n",
    "  model.eval()\n",
    "  correct = 0\n",
    "  total = 0\n",
    "  all_preds = []\n",
    "  all_labels = []\n",
    "  with t.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "      if t.cuda.is_available():\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "      outputs = model(images)\n",
    "      _, predicted = t.max(outputs, 1)\n",
    "      total += labels.size(0)\n",
    "      correct += (predicted == labels).sum().item()\n",
    "      all_preds.extend(predicted.cpu().numpy())\n",
    "      all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "  accuracy = correct/total\n",
    "  print(\"Name: DIVYASHREE V\")\n",
    "  print(\"Reg.no: 212223230051\")\n",
    "  print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "  cm = confusion_matrix(all_labels, all_preds)\n",
    "  plt.figure(figsize=(8, 6))\n",
    "  print(\"Name: DIVYASHREE V\")\n",
    "  print(\"Reg.no: 212223230051\")\n",
    "  sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=test_dataset.classes, yticklabels=test_dataset.classes)\n",
    "  plt.xlabel(\"Predicted\")\n",
    "  plt.ylabel(\"Actual\")\n",
    "  plt.title(\"Confusion Matrix\")\n",
    "  plt.show()\n",
    "\n",
    "  print(\"Name: DIVYASHREE V\")\n",
    "  print(\"Reg.no: 212223230051\")\n",
    "  print(\"Classification Report:\")\n",
    "  print(classification_report(all_labels, all_preds, target_names=[str(i) for i in range(10)]))\n",
    "test_model(model, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136ce1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(model,image_index,dataset):\n",
    "  model.eval()\n",
    "  image,label=dataset[image_index]\n",
    "  if t.cuda.is_available():\n",
    "    image=image.to(device)\n",
    "\n",
    "  with t.no_grad():\n",
    "    output=model(image.unsqueeze(0))\n",
    "    _,predicted=t.max(output,1)\n",
    "  class_names=[str(i) for i in range(10)]\n",
    "  print(\"Name: VIDHIYA LAKSHMI S\")\n",
    "  print(\"Reg.no: 212223230238\")\n",
    "  plt.imshow(image.cpu().squeeze(0),cmap='gray')\n",
    "  plt.title(f\"Actual: {class_names[label]}\\nPredicted: {class_names[predicted.item()]}\")\n",
    "  plt.axis(\"off\")\n",
    "  plt.show()\n",
    "  print(f\"Actual: {class_names[label]}\\nPredicted: {class_names[predicted.item()]}\")\n",
    "predict_image(model,image_index=80,dataset=test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc51bf0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
